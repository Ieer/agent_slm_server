[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "agent_slm_server"
version = "0.1.0"
description = "Lightweight local Qwen + embedding OpenAI-compatible server"
authors = [ { name = "Ieer", email = "qinquan0808@outlook.com" } ]
readme = "README.md"
requires-python = ">=3.10"
license = { text = "Proprietary / Research" }
keywords = ["llm", "qwen", "fastapi", "embeddings", "openai-compatible"]
classifiers = [
  "Programming Language :: Python :: 3",
  "License :: Other/Proprietary License",
  "Operating System :: OS Independent",
]
dependencies = [
  "fastapi>=0.95,<1.0",
  "uvicorn>=0.22,<0.36",
  "transformers>=4.33.0,<5.0.0",
  "sentence-transformers>=2.2.2,<3.0.0",
  "torch>=2.0.0",
  "psutil>=5.9",
  "pydantic>=2.0",
]

[tool.setuptools.packages.find]
where = ["src"]
include = ["agent_slm_server*"]
namespaces = false

[project.optional-dependencies]
quant = ["bitsandbytes>=0.41.0", "accelerate>=0.21.0"]
# 新增：llama.cpp / GGUF 後端支持
llama = ["llama-cpp-python>=0.2.84"]
# 開發與測試工具
dev = [
  "ruff>=0.6.0",
  "mypy>=1.10.0",
  "black>=24.3.0",
  "isort>=5.13.0",
  "pytest>=8.0.0",
  "pytest-asyncio>=0.23.0",
  "httpx>=0.28.0",
  "types-requests",
]
# 高度優化 / 量化執行（包含 quant 與其他可選套件）
optimized = [
  "bitsandbytes>=0.41.0",
  "accelerate>=0.21.0",
  "tiktoken>=0.7.0",
  "sse-starlette>=3.0.0",
  "openai>=1.0.0",
]
 # 文件建站（MkDocs）
 docs = [
   "mkdocs>=1.6.0",
   "mkdocs-material>=9.5.0",
   "mkdocstrings[python]>=0.25.0",
   "pymdown-extensions>=10.0",
 ]

[tool.ruff]
line-length = 120
select = ["E", "F", "I", "B", "UP", "ASYNC", "C4", "TID", "PL"]
ignore = ["E203", "E501"]

[tool.black]
line-length = 120
target-version = ["py311"]

[tool.isort]
profile = "black"
line_length = 120

[tool.mypy]
python_version = "3.11"
ignore_missing_imports = true
strict = false
show_error_codes = true

[tool.pytest.ini_options]
asyncio_mode = "auto"
addopts = "-q"

[tool.coverage.run]
branch = true
source = ["."]
